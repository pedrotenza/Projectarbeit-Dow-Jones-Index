{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn import metrics\n",
    "import numpy as npw\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"../data/data/aapl_raw_data.csv\")\n",
    "data.shape\n",
    "data.tail(1)\n",
    "\n",
    "data = data.iloc[:10747]\n",
    "\n",
    "data.tail(1)\n",
    "\n",
    "\n",
    "data.isnull().sum()\n",
    "data=data.fillna(0)  # Filling null values with zero\n",
    "data.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "#data[\"date\"] = data[\"date\"].astype(float)\n",
    "data[\"open\"] = data[\"open\"].astype(float)\n",
    "data[\"high\"] = data[\"high\"].astype(float)\n",
    "data[\"low\"] = data[\"low\"].astype(float)\n",
    "data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "data[\"adjusted_close\"] = data[\"adjusted_close\"].astype(float)\n",
    "data[\"change_percent\"] = data[\"change_percent\"].astype(float)\n",
    "data[\"avg_vol_20d\"] = data[\"avg_vol_20d\"].astype(float)\n",
    "\n",
    "data[\"close\"] = data[\"close\"].astype(float)\n",
    "\n",
    "#print(data.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "x_data = data[[ 'open', 'high', 'low', 'volume','adjusted_close', 'change_percent', 'avg_vol_20d']].values\n",
    "y_data = data[\"close\"].values.reshape(-1, 1)  # Reshape y_data if it's 1D\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to Tensors\n",
    "x_feature_tensors = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_feature_tensors = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(x_feature_tensors) * 0.67)\n",
    "x_train, x_test = x_feature_tensors[:train_size], x_feature_tensors[train_size:]\n",
    "y_train, y_test = y_feature_tensors[:train_size], y_feature_tensors[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fitting the MinMaxScaler to training data using fit_transform and then\n",
    "#  test data only transform\n",
    "x_train_scaled = scaler.fit_transform(x_train.detach().numpy())\n",
    "x_test_scaled = scaler.transform(x_test.detach().numpy())  # Use transform, not fit_transform\n",
    "\n",
    "y_train_scaled = scaler.fit_transform(y_train.detach().numpy())\n",
    "y_test_scaled = scaler.transform(y_test.detach().numpy())  # Use transform, not fit_transform\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "window_size = 50\n",
    "test_window_size = 50\n",
    "hidden_dim = 64\n",
    "n_layers = 4\n",
    "batch_evaluation_frequency = 10\n",
    "epochs = len(x_train_scaled) - window_size\n",
    "batch_size = 1\n",
    "input_size = x_train_scaled.shape[1]  # Input size based on your dataset\n",
    "output_size = 1  # Output size (for regression task)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projectarbeit-Dow-Jones-Index\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Train Loss: 9.03335603652522e-05, Validation Loss: 3.187233960488811e-05\n",
      "Iteration 2000, Train Loss: 0.00016266644524876028, Validation Loss: 0.007436024956405163\n",
      "Iteration 3000, Train Loss: 0.00029523862758651376, Validation Loss: 0.013675990514457226\n",
      "Iteration 4000, Train Loss: 1.761840576364193e-05, Validation Loss: 1.0649879186530598e-05\n",
      "Iteration 5000, Train Loss: 0.000991955865174532, Validation Loss: 0.02531951293349266\n",
      "Iteration 1000, Train Loss: 0.0002084744191961363, Validation Loss: 0.00011452690523583442\n",
      "Iteration 2000, Train Loss: 0.0002718893811106682, Validation Loss: 0.008175069466233253\n",
      "Iteration 3000, Train Loss: 0.00029494293266907334, Validation Loss: 0.013710128143429756\n",
      "Iteration 4000, Train Loss: 3.3245247323065996e-05, Validation Loss: 3.3632288250373676e-05\n",
      "Iteration 5000, Train Loss: 0.0010800770251080394, Validation Loss: 0.024367591366171837\n",
      "Iteration 1000, Train Loss: 7.177585212048143e-05, Validation Loss: 2.305101224919781e-05\n",
      "Iteration 2000, Train Loss: 0.00016095946193672717, Validation Loss: 0.007418871857225895\n",
      "Iteration 3000, Train Loss: 0.00033140997402369976, Validation Loss: 0.013437594287097454\n",
      "Iteration 4000, Train Loss: 2.6451127268956043e-05, Validation Loss: 2.384199069638271e-05\n",
      "Iteration 5000, Train Loss: 0.0011491221375763416, Validation Loss: 0.02429467812180519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projectarbeit-Dow-Jones-Index\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([6, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Train Loss: 0.00040262166294269264, Validation Loss: 0.000269543583272025\n",
      "Iteration 2000, Train Loss: 0.00048125427565537393, Validation Loss: 0.009138894267380238\n",
      "Iteration 3000, Train Loss: 0.00011017655924661085, Validation Loss: 0.014905576594173908\n",
      "Iteration 4000, Train Loss: 5.37687010364607e-05, Validation Loss: 1.5725339835626073e-05\n",
      "Iteration 5000, Train Loss: 0.00029185667517594993, Validation Loss: 0.0320160873234272\n",
      "Iteration 1000, Train Loss: 7.166488649090752e-05, Validation Loss: 2.4153188860509545e-05\n",
      "Iteration 2000, Train Loss: 0.00017196421686094254, Validation Loss: 0.007424874696880579\n",
      "Iteration 3000, Train Loss: 0.00022497221652884036, Validation Loss: 0.013632893562316895\n",
      "Iteration 4000, Train Loss: 3.0709223210578784e-05, Validation Loss: 5.0775775889633223e-05\n",
      "Iteration 5000, Train Loss: 0.001139795291237533, Validation Loss: 0.02313563972711563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projectarbeit-Dow-Jones-Index\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Train Loss: 0.00011962981807300821, Validation Loss: 0.00010496858158148825\n",
      "Iteration 2000, Train Loss: 0.0006779047544114292, Validation Loss: 0.010713930241763592\n",
      "Iteration 3000, Train Loss: 2.8394124456099235e-05, Validation Loss: 0.019662434235215187\n",
      "Iteration 4000, Train Loss: 0.0008034008205868304, Validation Loss: 0.0006578708998858929\n",
      "Iteration 5000, Train Loss: 0.011008888483047485, Validation Loss: 0.07786264270544052\n",
      "Iteration 1000, Train Loss: 0.00019668356981128454, Validation Loss: 0.00010512720473343506\n",
      "Iteration 2000, Train Loss: 0.0003265512641519308, Validation Loss: 0.008380747400224209\n",
      "Iteration 3000, Train Loss: 0.0002231731341453269, Validation Loss: 0.013674949295818806\n",
      "Iteration 4000, Train Loss: 2.3877815692685544e-05, Validation Loss: 3.743471097550355e-05\n",
      "Iteration 5000, Train Loss: 0.0007023843936622143, Validation Loss: 0.02552490495145321\n",
      "Iteration 1000, Train Loss: 8.398994395975024e-05, Validation Loss: 2.8963268050574698e-05\n",
      "Iteration 2000, Train Loss: 0.0001708886557025835, Validation Loss: 0.007500022649765015\n",
      "Iteration 3000, Train Loss: 0.0002847716095857322, Validation Loss: 0.013746976852416992\n",
      "Iteration 4000, Train Loss: 3.708049189299345e-05, Validation Loss: 3.7763740692753345e-05\n",
      "Iteration 5000, Train Loss: 0.0012313727056607604, Validation Loss: 0.0238109789788723\n",
      "Iteration 3000, Train Loss: 3.5986446164315566e-05, Validation Loss: 0.01639716885983944\n",
      "Iteration 3000, Train Loss: 0.0002802589151542634, Validation Loss: 0.014102713204920292\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Update the test window with the scalar value\u001b[39;00m\n\u001b[0;32m    109\u001b[0m new_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[predicted_close_scalar]]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 110\u001b[0m x_test_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[0;32m    113\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scalar]])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled, x_test_scaled, y_test_scaled,\n",
    "# input_size, output_size, test_window_size, scaler are available\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_scaled, y_train_scaled, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Hyperparameter search space\n",
    "search_space = {\n",
    "    'learning_rate': [0.00001, 0.00005, 0.0001],\n",
    "    'window_size': [3, 5, 6],\n",
    "    'hidden_dim': [64, 128, 256],\n",
    "    'n_layers': [10, 11, 12],\n",
    "    'batch_evaluation_frequency': [4, 5, 6]\n",
    "}\n",
    "\n",
    "# Best Parameters: {'learning_rate': 5e-05, 'window_size': 5, 'hidden_dim': 128,\n",
    "# 'n_layers': 11, 'batch_evaluation_frequency': 7}\n",
    "\n",
    "# Best Parameters: {'learning_rate': 0.0001, 'window_size': 10, 'hidden_dim': 256,\n",
    "# 'n_layers': 10, 'batch_evaluation_frequency': 5}\n",
    "\n",
    "\n",
    "\n",
    "# Number of random search iterations\n",
    "num_iterations = 10\n",
    "\n",
    "best_params = None\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    params = {\n",
    "        'learning_rate': random.choice(search_space['learning_rate']),\n",
    "        'window_size': random.choice(search_space['window_size']),\n",
    "        'hidden_dim': random.choice(search_space['hidden_dim']),\n",
    "        'n_layers': random.choice(search_space['n_layers']),\n",
    "        'batch_evaluation_frequency': random.choice(search_space['batch_evaluation_frequency'])\n",
    "    }\n",
    "\n",
    "    model = LSTMModel(input_size, params['hidden_dim'], params['n_layers'], output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    # Training using Walk-Forward Validation\n",
    "    for i in range(params['window_size'], len(x_train)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        start_idx = i - params['window_size']\n",
    "        end_idx = i\n",
    "        x_window = torch.tensor(x_train[start_idx:end_idx], dtype=torch.float32)\n",
    "        y_window = torch.tensor(y_train[start_idx:end_idx], dtype=torch.float32)\n",
    "        x_window = x_window.view(1, params['window_size'], input_size)\n",
    "\n",
    "        hidden = model.init_hidden(1)\n",
    "        outputs, hidden = model(x_window, hidden)\n",
    "        loss = criterion(outputs, y_window)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % params['batch_evaluation_frequency'] == 0:\n",
    "            with torch.no_grad():\n",
    "                x_val_window = torch.tensor(x_val[:params['window_size']], dtype=torch.float32)\n",
    "                y_val_window = torch.tensor(y_val[:params['window_size']], dtype=torch.float32)\n",
    "                x_val_window = x_val_window.view(1, params['window_size'], input_size)\n",
    "\n",
    "                hidden = model.init_hidden(1)\n",
    "                val_outputs, _ = model(x_val_window, hidden)\n",
    "                val_loss = criterion(val_outputs, y_val_window)\n",
    "\n",
    "                if i % 1000 == 0:  # Print every 1000 iterations\n",
    "                    print(f\"Iteration {i}, Train Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "\n",
    "    if best_params is None:\n",
    "        best_params = params\n",
    "        best_params['val_loss'] = val_loss.item()\n",
    "    elif val_loss < best_params['val_loss']:\n",
    "        best_params = params\n",
    "        best_params['val_loss'] = val_loss.item()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "num_future_days = 5\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        last_test_window_tensor = x_test_window\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(last_test_window_tensor, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "        # Update the test window with the scalar value\n",
    "        #x_test_window = torch.cat((x_test_window[:, 1:, :], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=1)\n",
    "        x_test_window = torch.cat((x_test_window[:, :, 1:], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=2)\n",
    "\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 3, 1])\n",
      "Size of new_x_test_window: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have your x_test_window and predicted_close_scalar tensors\n",
    "x_test_window = torch.randn(1, 3, 7)  # Example size, replace with your actual data\n",
    "predicted_close_scalar = torch.randn(1, 1, 1)  # Example size, replace with your actual data\n",
    "\n",
    "# Ensure the dimensions match for concatenation\n",
    "predicted_close_scalar = predicted_close_scalar.expand(-1, 3, -1)\n",
    "\n",
    "# Concatenate along the second dimension\n",
    "new_x_test_window = torch.cat((x_test_window, predicted_close_scalar), dim=2)\n",
    "\n",
    "# Print the sizes to verify\n",
    "print(\"Size of x_test_window:\", x_test_window.size())\n",
    "print(\"Size of predicted_close_scalar:\", predicted_close_scalar.size())\n",
    "print(\"Size of new_x_test_window:\", new_x_test_window.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 1, 1])\n",
      "Predicted Close for Day 1: [21.143133]\n",
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 1, 1])\n",
      "Predicted Close for Day 2: [21.14314]\n",
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 1, 1])\n",
      "Predicted Close for Day 3: [21.143135]\n",
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 1, 1])\n",
      "Predicted Close for Day 4: [21.143139]\n",
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 1, 1])\n",
      "Predicted Close for Day 5: [21.14314]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have defined your model, scaler, and other necessary parameters\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        last_test_window_tensor = x_test_window\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scalar, _ = model(last_test_window_tensor, hidden)\n",
    "\n",
    "        # Ensure the correct shape for predicted_close_scalar\n",
    "        predicted_close_scalar = predicted_close_scalar.view(1, 1, 1)\n",
    "\n",
    "        # Create a new tensor with the desired shape [1, 3, 1]\n",
    "        predicted_close_tensor = torch.zeros(1, 3, 1)\n",
    "        predicted_close_tensor[:, :, 0] = predicted_close_scalar[:, 0, 0]\n",
    "\n",
    "        print(f\"Size of x_test_window: {x_test_window.size()}\")\n",
    "        print(f\"Size of predicted_close_scalar: {predicted_close_scalar.size()}\")\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], predicted_close_tensor), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform(predicted_close_tensor[0].detach().numpy())\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0]}\")\n",
    "\n",
    "        # Update x_test_window for the next iteration\n",
    "        x_test_window = updated_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 3, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 3 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_test_window[:, :, \u001b[38;5;241m1\u001b[39m:], predicted_close_scalar), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Print or store the predicted value for the current day\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Close for Day \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_close[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 3 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "num_future_days = 5\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        last_test_window_tensor = x_test_window\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scalar, _\n",
    "\n",
    "        # Ensure the correct shape for predicted_close_scalar\n",
    "        predicted_close_scalar = predicted_close_scalar.view(1, -1, 1)\n",
    "\n",
    "        # Explicitly reshape to match the desired size [1, 3, 1]\n",
    "        predicted_close_scalar = predicted_close_scalar.expand(1, 3, 1)\n",
    "\n",
    "        print(f\"Size of x_test_window: {x_test_window.size()}\")\n",
    "        print(f\"Size of predicted_close_scalar: {predicted_close_scalar.size()}\")\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], predicted_close_scalar), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar[:,:,0].item()]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0]}\")\n",
    "\n",
    "        # Update x_test_window for the next iteration\n",
    "        x_test_window = updated_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scaled: torch.Size([1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[54], line 19\u001b[0m\n",
      "\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of predicted_close_scaled: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_close_scaled\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n",
      "\u001b[1;32m---> 19\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_close_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n",
      "\u001b[0;32m     22\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scaled[:,:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), predicted_close_scaled[:,:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), predicted_close_scaled[:,:,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]])\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": [
    "num_future_days = 5\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        last_test_window_tensor = x_test_window\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(last_test_window_tensor, hidden)\n",
    "\n",
    "\n",
    "        print(f\"Size of x_test_window: {x_test_window.size()}\")\n",
    "        print(f\"Size of predicted_close_scaled: {predicted_close_scaled.size()}\")\n",
    "\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], predicted_close_scaled), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scaled[:,:,0].item(), predicted_close_scaled[:,:,1].item(), predicted_close_scaled[:,:,2].item()]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0]}\")\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 7, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of x_test_window:\", x_test_window.size())\n",
    "print(\"Size of predicted_close_scalar:\", predicted_close_scalar.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Reshape predicted_close_scalar to match the dimensions of x_test_window\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[0;32m     24\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_test_window[:, :, \u001b[38;5;241m1\u001b[39m:], predicted_close_scalar), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "num_future_days = 5\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        last_test_window_tensor = x_test_window\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(last_test_window_tensor, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Reshape predicted_close_scalar to match the dimensions of x_test_window\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], predicted_close_scalar), dim=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m  predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Reshape predicted_close_scalar to match the dimensions of x_test_window\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m  predicted_close_scalar \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m  \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[0;32m     19\u001b[0m  updated_window \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_test_window, predicted_close_scalar), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(x_test_window, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "\n",
    "\n",
    "       # Reshape predicted_close_scalar to match the dimensions of x_test_window\n",
    "        predicted_close_scalar = torch.unsqueeze(torch.unsqueeze(torch.tensor(predicted_close_scalar, dtype=torch.float32), dim=0), dim=2)\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window, predicted_close_scalar), dim=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "        # Update x_test_window with the new window\n",
    "        x_test_window = updated_window\n",
    "\n",
    "# If needed, you can further update the model parameters based on the new data\n",
    "# For example, you might want to retrain the model with the updated data\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window[:, :, :]: torch.Size([1, 3, 7])\n",
      "Size of torch.tensor([[[predicted_close_scalar]]]): torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Assuming x_test_window is a PyTorch tensor and predicted_close_scalar is a scalar value\n",
    "print(\"Size of x_test_window[:, :, :]:\", x_test_window[:, :, :].size())\n",
    "print(\"Size of torch.tensor([[[predicted_close_scalar]]]):\", torch.tensor([[[predicted_close_scalar]]]).size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_test_window: torch.Size([1, 3, 7])\n",
      "Size of predicted_close_scalar: torch.Size([1, 3, 1])\n",
      "Size of new_x_test_window: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have your x_test_window and predicted_close_scalar tensors\n",
    "x_test_window = torch.randn(1, 3, 7)  # Example size, replace with your actual data\n",
    "predicted_close_scalar = torch.randn(1, 1, 1)  # Example size, replace with your actual data\n",
    "\n",
    "# Ensure the dimensions match for concatenation\n",
    "predicted_close_scalar = predicted_close_scalar.expand(-1, 3, -1)\n",
    "\n",
    "# Concatenate along the second dimension\n",
    "new_x_test_window = torch.cat((x_test_window, predicted_close_scalar), dim=2)\n",
    "\n",
    "# Print the sizes to verify\n",
    "print(\"Size of x_test_window:\", x_test_window.size())\n",
    "print(\"Size of predicted_close_scalar:\", predicted_close_scalar.size())\n",
    "print(\"Size of new_x_test_window:\", new_x_test_window.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[0;32m     17\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scalar]])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(x_test_window, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        updated_window = torch.cat((x_test_window[:, :, :], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "        # Update x_test_window with the new window\n",
    "        x_test_window = updated_window\n",
    "\n",
    "# If needed, you can further update the model parameters based on the new data\n",
    "# For example, you might want to retrain the model with the updated data\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming x_test_window has shape (1, window_size, num_features)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[0;32m     18\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scalar]])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(x_test_window, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        # Assuming x_test_window has shape (1, window_size, num_features)\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "        # Update x_test_window with the new window\n",
    "        x_test_window = updated_window\n",
    "\n",
    "# If needed, you can further update the model parameters based on the new data\n",
    "# For example, you might want to retrain the model with the updated data\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming x_test_window has shape (1, window_size, num_features)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m updated_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[0;32m     18\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scalar]])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(x_test_window, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        # Assuming x_test_window has shape (1, window_size, num_features)\n",
    "        updated_window = torch.cat((x_test_window[:, :, 1:], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "        # Update x_test_window with the new window\n",
    "        x_test_window = updated_window\n",
    "\n",
    "# If needed, you can further update the model parameters based on the new data\n",
    "# For example, you might want to retrain the model with the updated data\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m predicted_close_scalar \u001b[38;5;241m=\u001b[39m predicted_close_scaled\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Update the test window by including the latest predicted value\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m x_test_window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_close_scalar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert the predicted value to the original scale if needed\u001b[39;00m\n\u001b[0;32m     19\u001b[0m predicted_close \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[predicted_close_scalar]])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "num_future_days = 5\n",
    "\n",
    "# Initialize x_test_window with the last values from the validation set\n",
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "for day in range(num_future_days):\n",
    "    with torch.no_grad():\n",
    "        # Use the last predicted values as input for the next prediction\n",
    "        hidden = model.init_hidden(1)\n",
    "        predicted_close_scaled, _ = model(x_test_window, hidden)\n",
    "\n",
    "        # Extract the scalar value from the predicted_close_scaled tensor\n",
    "        predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "        # Update the test window by including the latest predicted value\n",
    "        x_test_window = torch.cat((x_test_window[:, :, 1:], torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)), dim=2)\n",
    "\n",
    "        # Convert the predicted value to the original scale if needed\n",
    "        predicted_close = scaler.inverse_transform([[predicted_close_scalar]])\n",
    "\n",
    "        # Print or store the predicted value for the current day\n",
    "        print(f\"Predicted Close for Day {day + 1}: {predicted_close[0][0]}\")\n",
    "\n",
    "# If needed, you can further update the model parameters based on the new data\n",
    "# For example, you might want to retrain the model with the updated data\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x_test_window: torch.Size([1, 3, 7])\n",
      "Dimensions of predicted_close_scalar: torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of x_test_window\n",
    "print(\"Dimensions of x_test_window:\", x_test_window.size())\n",
    "\n",
    "# Print dimensions of predicted_close_scalar\n",
    "print(\"Dimensions of predicted_close_scalar:\", torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_close_scalar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Update the test window with the scalar value\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted_close_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[\u001b[43mpredicted_close_scalar\u001b[49m]]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print sizes of tensors\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_test_window[:, 1:, :].size():\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_test_window[:, \u001b[38;5;241m1\u001b[39m:, :]\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_close_scalar' is not defined"
     ]
    }
   ],
   "source": [
    "# Update the test window with the scalar value\n",
    "predicted_close_tensor = torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)\n",
    "\n",
    "# Print sizes of tensors\n",
    "print(\"x_test_window[:, 1:, :].size():\", x_test_window[:, 1:, :].size())\n",
    "print(\"predicted_close_tensor.size():\", predicted_close_tensor.size())\n",
    "\n",
    "# Concatenate tensors\n",
    "x_test_window = torch.cat((x_test_window[:, 1:, :], predicted_close_tensor), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_value_31_07_2024: 195.61\n",
      "\n",
      "real_value_01_08_2024: 192.58\n",
      "real_value_02_08_2024: 191.17\n"
     ]
    }
   ],
   "source": [
    "real_value_31_07_2024 = pd.read_csv(\"../data/data/aapl_raw_data.csv\").loc[10747, 'close']\n",
    "real_value_01_08_2024 = pd.read_csv(\"../data/data/aapl_raw_data.csv\").loc[10748, 'close']\n",
    "real_value_02_08_2024 = pd.read_csv(\"../data/data/aapl_raw_data.csv\").loc[10749, 'close']\n",
    "print(f\"real_value_31_07_2024: {real_value_31_07_2024}\")\n",
    "print(\"\")\n",
    "print(f\"real_value_01_08_2024: {real_value_01_08_2024}\")\n",
    "print(f\"real_value_02_08_2024: {real_value_02_08_2024}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_close_scalar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Update the test window with the scalar value\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted_close_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[\u001b[43mpredicted_close_scalar\u001b[49m]]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print sizes of tensors\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_test_window[:, 1:, :].size():\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_test_window[:, \u001b[38;5;241m1\u001b[39m:, :]\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_close_scalar' is not defined"
     ]
    }
   ],
   "source": [
    "# Update the test window with the scalar value\n",
    "predicted_close_tensor = torch.tensor([[[predicted_close_scalar]]], dtype=torch.float32)\n",
    "\n",
    "# Print sizes of tensors\n",
    "print(\"x_test_window[:, 1:, :].size():\", x_test_window[:, 1:, :].size())\n",
    "print(\"predicted_close_tensor.size():\", predicted_close_tensor.size())\n",
    "\n",
    "# Concatenate tensors\n",
    "#x_test_window = torch.cat((x_test_window[:, 1:, :], predicted_close_tensor), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x_test_window[:, 1:]: torch.Size([1, 2, 7])\n",
      "Dimensions of predicted_close_scalar_array: (1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions of predicted_close_scalar_array:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_close_scalar_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Update the test window with the scalar value\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m x_test_window \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_window\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_close_scalar_array\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "x_test_window = torch.tensor(x_val[-params['window_size']:], dtype=torch.float32).view(1, params['window_size'], input_size)\n",
    "\n",
    "\n",
    "# Print the dimensions of x_test_window[:, 1:]\n",
    "print(\"Dimensions of x_test_window[:, 1:]:\", x_test_window[:, 1:].shape)\n",
    "\n",
    "# Extract the scalar value from the predicted_close_scaled tensor\n",
    "predicted_close_scalar = predicted_close_scaled.item()\n",
    "\n",
    "# Create an array with the scalar value\n",
    "predicted_close_scalar_array = np.array([[predicted_close_scalar]])\n",
    "\n",
    "# Print the dimensions of predicted_close_scalar_array\n",
    "print(\"Dimensions of predicted_close_scalar_array:\", predicted_close_scalar_array.shape)\n",
    "\n",
    "# Update the test window with the scalar value\n",
    "x_test_window = np.concatenate((x_test_window[:, 1:], predicted_close_scalar_array), axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
