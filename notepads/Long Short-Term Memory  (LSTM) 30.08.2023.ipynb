{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgaben zu Vertiefung AI-Engineer Modul 5 - Time-Series-Data\n",
    "\n",
    "Aufgabe 1: Time-Series-Data\n",
    "\n",
    "Identifizieren Sie im UCI Repository (oder von anderen Stellen) einen Datensatz mit temporaler \n",
    "Dynamik. Implementieren Sie ein Neuronales Netz mit dem “naiven Ansatz”, mehrere Instanzen \n",
    "nachrutschend in die Input Schicht zu geben. Evaluieren Sie diesen naiven Ansatz gegen eine \n",
    "Implementierung mittels rekurrenter Layer.\n",
    "\n",
    "https://archive.ics.uci.edu/datasets.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dow Jones Index\n",
    "Donated on 10/22/2014\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/312/dow+jones+index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.9.13)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as npw\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"../data/data/dow_jones_index.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "data[\"close\"] = data[\"close\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "data[\"open\"] = data[\"open\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "data[\"high\"] = data[\"high\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "data[\"low\"] = data[\"low\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "data[\"next_weeks_open\"] = data[\"next_weeks_open\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "data[\"next_weeks_close\"] = data[\"next_weeks_close\"].apply(lambda x: x.replace(\"$\", \"\"))\n",
    "\n",
    "data[\"close\"] = data[\"close\"].astype(float)\n",
    "data[\"open\"] = data[\"open\"].astype(float)\n",
    "data[\"high\"] = data[\"high\"].astype(float)\n",
    "data[\"low\"] = data[\"low\"].astype(float)\n",
    "data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "data[\"percent_change_price\"] = data[\"percent_change_price\"].astype(float)\n",
    "data[\"next_weeks_open\"] = data[\"next_weeks_open\"].astype(float)\n",
    "data[\"next_weeks_close\"] = data[\"next_weeks_close\"].astype(float)\n",
    "data[\"percent_change_next_weeks_price\"] = data[\"percent_change_next_weeks_price\"].astype(float)\n",
    "data[\"days_to_next_dividend\"] = data[\"days_to_next_dividend\"].astype(float)\n",
    "data[\"percent_return_next_dividend\"] = data[\"percent_return_next_dividend\"].astype(float)\n",
    "\n",
    "# Load the x_train and y_train data\n",
    "x_train = data[['open', 'high', 'low', 'volume', 'percent_change_price', 'next_weeks_open', 'next_weeks_close', 'percent_change_next_weeks_price', 'days_to_next_dividend', 'percent_return_next_dividend']].to_numpy()\n",
    "y_train = data[\"close\"].to_numpy()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.33, random_state=45)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size  # Define input_size as an attribute\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        h0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Ensure input has the shape [batch_size, sequence_length, input_size]\n",
    "        x = x.view(batch_size, -1, self.input_size)\n",
    "\n",
    "        out, (hidden, cell) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Select the last time step's output and apply the linear layer\n",
    "        return out\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 10\n",
    "output_size = 1\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "sequence_length = 1  # Keep this as 1 for your input data\n",
    "batch_size = 8\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "train_data = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create an instance of the LSTM model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMModel(input_size, hidden_dim, n_layers, output_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(outputs, batch_y.view(-1, 1))  # Ensure batch_y has the right shape\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        # Evaluate on testing set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(x_test_tensor)\n",
    "            val_loss = loss_function(val_outputs, y_test_tensor.view(-1, 1))  # Ensure y_test_tensor has the right shape\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Code for making predictions\n",
    "input_data = np.array([15.82, 16.72, 15.78, 239655616.0, 3.79267, 16.71, 15.97, -4.428490, 26.0, 0.182704])\n",
    "input_data_scaled = scaler.transform(input_data.reshape(1, -1))  # Scale the input data\n",
    "input_tensor = torch.tensor(input_data_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Ensure the input data has the same sequence length as the model's input\n",
    "# If sequence_length != 1, you need to repeat the input data to match the sequence length\n",
    "if sequence_length != 1:\n",
    "    input_tensor = input_tensor.repeat(1, sequence_length, 1)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction_tensor = model(input_tensor)\n",
    "predicted_value = prediction_tensor[0][0].item()\n",
    "\n",
    "print(\"Predicted Value:\", predicted_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
